{
 "metadata": {
  "name": "Code, Refactor, Test"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "(Opportunities for) Good Practices in Scientific Programming"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although at first glance it might look like it, this is **not an introduction** into the [Python](http://www.python.org) programming language (although we'll see a good chunk of its features along the way). We are just using Python, because it is a free and easy to grasp language that is well established in the scientific community. Anyone who is looking for an introduction to Python can find many good ones for various audiences on the web. Here are a few examples, but there are many more:\n",
      "\n",
      "* [The official Python tutorial](http://docs.python.org/tutorial)\n",
      "* [Dive into Python](http://www.diveintopython.net)\n",
      "* [Python for beginners](http://www.pythonforbeginners.com)\n",
      "* [Scientific Python lecture notes](http://scipy-lectures.github.io)\n",
      "\n",
      "This is **also not** a comprehensive overview of code refactoring and testing techniques -- many good books have been written about these topics, and this is one of them:\n",
      "\n",
      "* [Refactoring to patterns by Joshua Kerievsky](http://industriallogic.com/xp/refactoring)\n",
      "\n",
      "Instead of being a comprehensive something on something, this is merely **a protocol of a rather typical coding task** that has been, and will be, performed countless times in various flavors by many scientists. What may be different here, compared to most occasions, is that instead of stopping at the earliest possible stage that could be labeled \"task completed\", we'll spend just a few more minutes to help increase quality, longevity and re-usability of the resulting code.\n",
      "\n",
      "For this tutorial to be useful the reader (you!) should be already familiar with some programming language -- any, really. You should know what a variable and a function is, and that one can store numbers in lists and maybe arrays. If you, for example, have scripted anything in Matlab, you should have everything necessary to make sense of what follows below.\n",
      "\n",
      "**The actual task** in this example is to **write a parser for a text-based file format** produced by an [eye-tracker](). Our goal is to extract the time courses of gaze coordinates from the wealth of information in such a file and plot the spatial distribution of gaze positions across the entire recording session.\n",
      "\n",
      "We have three files to work with:\n",
      "\n",
      "- [gaze_snip1.txt](http://raw.github.com/neurodebian/psychotut/master/python/data/gaze_snip1.txt) (plus the [same file gzip-compressed](https://github.com/neurodebian/psychotut/raw/master/python/data/gaze_snip1.txt.gz)) and [gaze_snip2.txt](https://raw.github.com/neurodebian/psychotut/master/python/data/gaze_snip2.txt)\n",
      "\n",
      "  Two example files with a few dozen lines to give a sense of the variability of the (undocumented) syntax of the file format.\n",
      "\n",
      "- [gaze.txt.gz](https://raw.github.com/neurodebian/psychotut/master/python/data/gaze.txt.gz)\n",
      "\n",
      "  A compressed text file with data from a complete eye-tracking session -- several hundreds of thousands lines of raw data.\n",
      "  \n",
      "We'll start by working with the small example snippets to develop the parser and will eventually test it out on the big file with real data to see how it performs. Once this is done, we'll adjust the code to be more readable, robust and tested to increase its longevity."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To follow this tutorial, download the files listed above into a subdirectory named ``data``. Start an [IPython]() session and successively copy the respective code bits into the IPython console. If you have a recent IPython version (from 0.13 onwards) you can also [download this notebook](https://github.com/neurodebian/psychotut/raw/master/python/Code%2C%20Refactor%2C%20Test.ipynb) into the directory that contains the ``data`` folder. You can then work on this tutorial with the fantastic [IPython notebook](http://ipython.org/notebook.html). Start a notebook server (by executing ``ipython notebook --pylab inline``) in this directory using a terminal. This will open a browser window where you can select the notebook. Afterwards you can start working directly in the browser -- pure magic.\n",
      "\n",
      "If you do not have IPython available it is possible to perform most tasks using a pure Python interpreter running in a terminal. However, this is **not recommended** as it is complicated, inconvenient, and will leave you with a false impression of scientific coding in Python. For interactive work in Python, use *Interactive Python*: IPython.\n",
      "\n",
      "A straightforward way to obtain a suitable computing environment for **any** platform is the [NeuroDebian]() virtual machine. Visit http://neuro.debian.net, select an operating system of your choice, and follow the installation instructions. The virtual machine will greet you with a welcome wizard when started for the first time. Work you way through it to update the system. When prompted, select 'Python scientific software stack' for installation. This will download and install additional 500MB of software, so please be patient.\n",
      "\n",
      "Depending on the version of the virtual machine, you may want to install the ``ipython-notebook`` package as well, in order to work directly with this notebook.\n",
      "\n",
      "And now we are good to go..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prototyping the Parser"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Python is known for its utility for prototyping algorithms -- that is to quickly develop a rough sketch of an algorithm that actually runs to practically explore potential problems and runtime challenges. Quite often, however, scientific software never leaves this prototype stage, because it is \"good enough\" (TM) and the cost of a  proper/improved re-implementation does not outweight the perceived value of potential benefits.\n",
      "\n",
      "Here we'll do what is common (albeit not good) practice and simply start hacking...\n",
      "\n",
      "You'll quickly realize that we do not need to write much code, because we can use available libraries. Python has **a lot** of built-in libraries for all kinds of things, hence it earned the tag-line \"batteries included\". For example, Python might be the only language that has support for converting between color spaces as part of its standard library (see [colorsys](http://docs.python.org/library/colorsys.html)). In Python libraries are called modules, and they can be loaded via the *import* statement. You can see a list of all modules included in the standard Python distribution in the [library reference](http://docs.python.org/library/). One of the most frequently used modules is [os](http://docs.python.org/library/os.html). It offer access to operating system features in a cross-platform fashion. In the first code snippet we combine a directory name with the filename of our first example file to compose a relative filepath -- one that uses the correct path delimiter on all platforms. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "datafilename = os.path.join('data', 'gaze_snip1.txt')\n",
      "print datafilename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll notice the ``os.path.join`` construct. With this code we are accessing the ``join()`` function in the ``path`` submodule of the ``os`` system module. In Python each module has its own namespace, meaning it is OK to have several functions with the same name provided by different modules. Consequently, name collisions in Python are pretty much a non-issue when compared to the situation in C or MATLAB.\n",
      "\n",
      "If you ever need help regarding tohe purpose or types of arguments of a function, Python provides a ``help()`` function that is pretty convenient (we'll see below how this actually works). Even more convenient is that IPython can pull this documentation up automatically while you type a function call and hit the opening parentheses. It can also do autocompletion. Try it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(os.path.join)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are ready to dive deep into the fun of working with Python. Opening a file and printing its content is almost trivial: The built-in ``open()`` function takes a filename and returns a file handler that, in turn, supports to iteratively return a text file's content line by line when used in a for loop. You'll notice the lack of any parentheses. Where the body of the loop would be wrapped in parentheses in other languages, Python uses the code indentation level to determine this information. This reduces the variablity of look and feel of code written by different developers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in open(datafilename):\n",
      "    print line,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So how do we write that parser without access to the file format specifications -- we'll use a dangerous combination of intuition and common sense.\n",
      "\n",
      "From the content of the first example snippet we could get the idea that the first 76 lines are some kind of header. So let's modify the code to skip the first 76 lines by introducing a line counter and an ``if`` condition."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skiplines = 76\n",
      "for line in open(datafilename):\n",
      "    if skiplines > 0:\n",
      "        skiplines -= 1\n",
      "        continue\n",
      "    print line,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not bad. Actually, with the built-in [``enumerate()``](http://docs.python.org/2/library/functions.html#enumerate) function Python has a much more elegant way of adding a counter variable. The snippet below does the exact same thing as before -- just with less and more readable code. Moreover, we cannot forget incrementing the counter when the code gets more complicated later on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76:\n",
      "        continue\n",
      "    print line,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This looks already pretty good with just four lines of code, but there is a status message left in the output lines that we do not want. The most straightforward way to get rid of it is to amend the ``if`` clause and add another line exclusion condition. We can benefit from one of the methods that Python provides for strings (and yes, it also has [``endswith()``](http://docs.python.org/library/stdtypes.html#string-methods))."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    print line,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Done -- almost. But instead of just printing the relevant lines we need to store the data. In many languages [lists](http://docs.python.org/tutorial/datastructures.html#more-on-lists) are extensible containers that can hold an arbitrary amount of data. The same holds for Python -- with a few extra features that we will ignore for now. Lists definition and access to elements works like it is shown below. This is pretty similar to other languages. Note however, the handy way to access list elements relative to the end of the list by using negative index values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = [1, 2, 3, 4]\n",
      "print l[0]\n",
      "print l[3]\n",
      "print l[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is more than one way to extend and modify Python lists. The only one we'll need is the ``append()`` method that -- the name suggests it -- appends a single element to the end of a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l.append(10)\n",
      "print l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That should give us all we need: We create an empty list at the start and append all relevant data lines to it while looping over all lines in the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    data.append(line)\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, that worked somewhat. We have a list element per data sample, but everything is still in text form interspersed with TAB and NEWLINE control characters. This is nothing we can do computing with. Luckily Python is fully equiped with pretty versatile text processing tools. All strings have a ``split()`` method that, by default, splits a string into its whitespace-delimited segments -- just what we need."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "someline = data[0]\n",
      "lineitems = someline.split()\n",
      "lineitems"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last field in every lines seems to be some sort of garbage, so we'll strip it off. Python lists support slicing (subselection of elements) using a [START:STOP:STEP] notation, where START and STEP are optional. With the aforementioned option of using negative indices we have to possible ways to select the first four elements from a five element list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lineitems[:4]\n",
      "print lineitems[:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's merge this functionality into our existing code, and we'll be able to produce a list with an element for each data sample, where each element is a 4-item list with the numbers we want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    data.append(line.split()[:-1])\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try it out. We compute the duration of the recording from the first column. We have heard that this is the time stamp in milliseconds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = data[-1][0] - data[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrgh, our \"numbers\" are still text (or strings), and we cannot do meaningful substraction with them. Whoever said that \"in Python you do not need to care about data types\" was obviously wrong. Consequently, Python provides functions to convert text into basic data types such as integers (``int``) and floating point numbers (``float``)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "int('1234')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float('1234')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For convenience we will convert all our numbers into floats. And because it is a lot to type, we'll only do it for the first three in each line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    lineitems = line.split()[:-1]\n",
      "    data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = data[-1][0] - data[0][0]\n",
      "dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally something to compute with: the recording duration of our data snippet was 12 ms. Now let's plot the gaze coordinates. The ``X`` coordinate is in the second column, the ``Y` coordinate in the third. We have a list of lists, so let's first select all samples and then the second item in each."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[:][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm, that did not work. What about"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[:,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This doesn't seem to be right either. Nested lists do not seem to be the right container for our data, in order to access its content in the way we want to.\n",
      "\n",
      "A more appropriate container is an ``array``. This is a (multidimensional/multi-axis) field of number of the same type. Most language offer such a data container, because it is useful for storing lots of data and accessing it at low cost. In Python the [``numpy``](http://www.numpy.org) package provides arrays -- and they are almost like in MATLAB. However, MATLAB users will appreciate the [NumPy for MATLAB users guide](http://wiki.scipy.org/NumPy_for_Matlab_Users) that pinpoints a few key differences.\n",
      "\n",
      "Thankfully, converting our list of lists into a two-dimensional array is pretty simple -- after first importing the ``numpy`` module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "darr = np.array(data)\n",
      "darr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "darr.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arrays support additional modes of slicing (this a more complicated topic that you should [read more about](http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)), so what caused an error before now does the right thing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "darr[:,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Making a plot of the gaze trajectory over the 12 ms is now pretty easy. We are using [matplotlib](http://matplotlib.org/) and specifically its ``pyplot`` module's ``plot`` function to plot X against Y coordinates for each data sample. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as pl\n",
      "pl.plot(darr[:,1], darr[:,2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It seems like we have all pieces to do what we want, so let's put them together. Here is the part for data import."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafilename = os.path.join('data', 'gaze_snip1.txt')\n",
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    lineitems = line.split()[:-1]\n",
      "    data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "darr = np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how it performs on our second data file. We only need to edit the file name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafilename = os.path.join('data', 'gaze_snip2.txt')\n",
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    lineitems = line.split()[:-1]\n",
      "    data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "darr = np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm, not so good. It seems like our concept of the file format is not optimal. At some point the parser is trying to convert a text string into a floating point number. It fails and raises an exception. Exceptions, like in C++ or other language are a way to communicate errors.\n",
      "\n",
      "An interesting aspect of exceptions is that they can be intercepted and acted upon. So let's modify the code to catch this ``ValueError`` and take a look at the line that causes our program to fail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafilename = os.path.join('data', 'gaze_snip2.txt')\n",
      "data = []\n",
      "for lineno, line in enumerate(open(datafilename)):\n",
      "    if lineno < 76 or line.startswith('SFIX'):\n",
      "        continue\n",
      "    lineitems = line.split()[:-1]\n",
      "    try:\n",
      "        data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "    except ValueError, e:\n",
      "        print e\n",
      "        print line\n",
      "darr = np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indeed, it doesn't look like a gaze coordinate sample at all. Let's take a look at this other file. We can use IPython's ability to execute arbitrary shell command (by using an explamation mark as a prefix), but you can also open the file in a text editor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n150 $datafilename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, this file looks significantly different form the first one. Especially our assumption that the first 76 lines are a (static) header seems to be wrong. We need to find the common pattern and adjust our code accordingly."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Refactor for Re-use"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a good point to look at our code and refactor it. Refactoring means to restructure the code, identify or establish reusable component with the goal to make the code more readable, and easier to maintain.\n",
      "\n",
      "The first annoying thing that we need to address is that we are forced to edit to parser code in order to read another file. If we would want to read two data files and process them together for further analysis, we would even need to copy the parser code. However, code copies are **always bad** as errors need to be fixed in multiple locations -- human errors are just a matter of time.\n",
      "\n",
      "It is much better to place the parser code into a reusable function. A function that takes one argument: the name of the file that is to be read."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_data(filename):\n",
      "    data = []\n",
      "    for lineno, line in enumerate(open(filename)):\n",
      "        if lineno < 76 or line.startswith('SFIX'):\n",
      "            continue\n",
      "        lineitems = line.split()[:-1]\n",
      "        data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "    return np.array(data)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading the first data snippet is not affected by this change."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_data(os.path.join('data', 'gaze_snip1.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While we are at restructuring the code, let's look at the rest. We already know that our assumption of 76 header lines is wrong. Now imagine what a colleague would think that sees this code for the first time. She sees a magic number \"76\" and a magic string \"SFIX\" that cause a line to be ignored from further processing.\n",
      "\n",
      "We could make it a lot easier for our colleagues by actually spelling out what we intend to do. Let's take all our line exclusion conditions and move them into a function ``is_dataline()`` that takes line number and actual line content as arguments. Here is what it looks like now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_dataline(lineno, line):\n",
      "    return lineno > 76 and not line.startswith('SFIX')\n",
      "    \n",
      "def load_data(filename):\n",
      "    data = []\n",
      "    for lineno, line in enumerate(open(filename)):\n",
      "        if not is_dataline(lineno, line):\n",
      "            continue\n",
      "        lineitems = line.split()[:-1]\n",
      "        data.append([float(lineitems[0]), float(lineitems[1]), float(lineitems[2])])\n",
      "    return np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this move we have removed two mystical values (76 and ``SFIX``) from our code in ``load_data()`` and at the same time made it obvious what kind of lines are supposed to be ignore. Our colleagues will appreciate this move if they ever need to work on our code.\n",
      "\n",
      "Something similar can be done with the next two lines. Here we decide what to store from each line. If we also move this code into its own function, we end up with code for ``load_data()`` that is very simple to read."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_line_items(line):\n",
      "    items = line.split()[:-1]\n",
      "    return [float(items[0]), float(items[1]), float(items[2])]\n",
      "\n",
      "def is_dataline(lineno, line):\n",
      "    return lineno > 76 and not line.startswith('SFIX')\n",
      "    \n",
      "def load_data(filename):\n",
      "    data = []\n",
      "    for lineno, line in enumerate(open(filename)):\n",
      "        if not is_dataline(lineno, line):\n",
      "            continue\n",
      "        data.append(get_line_items(line))\n",
      "    return np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But we need to remember that our nicely refactored code still doesn't work on the second file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clearly we are trying to process a line that should not be processed. All we need to do is to amend the exclusion conditions to get rid of such lines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_dataline(lineno, line):\n",
      "    return lineno > 76 and not line.startswith('SFIX') and not line.startswith('MSG')\n",
      "\n",
      "load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, not quite -- but a different error at least.\n",
      "\n",
      "But before we look into this further let's take a step back and reconsider what we just did... We made an isolated change in the ``is_dataline()`` function, because we redefined what we consider a line for a gaze sample to be like. A colleague, our our future self looking at this change in six months would have had a much harder time figuring out what it is about, if the change would be hidden somewhere in the code of a long ``load_data()`` function, right?\n",
      "\n",
      "Now back to the bug. If we stare long and hard on the content of the second file, we'll see that there are many lines past the 76th that contain no relevant data. Maybe it is time for a more radical change.\n",
      "\n",
      "What could be a better criterion for identifying a line with data?\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "They all seem to start with a digit, right? So let's find a way to test for that. First, we grab the very first item on each line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_line = '4654784\t  638.4\t  271.8\t 4907.0\t...'\n",
      "first_item = good_line.split()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And again Python has everything built-in -- you'll quickly get used to this convenience."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_item # type <dot> and hit tab\n",
      "first_item.isdigit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Actually, we can do this even simpler. Strings in Python are essentially sequences of characters and we can use the standard approach to access the first character."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print good_line[0]\n",
      "good_line[0].isdigit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That seems to do it, so we can simplify our ``is_dataline()`` condition. Again, for a future developer it will be obvious from this change that we redefined out concept of a dataline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_dataline(lineno, line):\n",
      "    return line[0].isdigit()\n",
      "\n",
      "load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What? Let's open the file again and look at the data lines...\n",
      "\n",
      "We have hit the one common problem in almost all sciences -- missing data. This participant must have blinked, hence no coordinate data was available. Our parser needs to deal with this, hence we use a special value for this case: \"not a number\" or ``NaN``. We'll use this number whenever the conversion to float fails -- we already know that this would yield a ``ValueError`` exception, so we can intercept it and act accordingly.\n",
      "\n",
      "> Note: Some people will become nervous now. Aren't exceptions for handling exceptional cases? Aren't eye-blinks to be expected in eye-gaze recordings? Should we therefore explcitely test for the case of missing data? I'll leave the burden of that decision to you, but I personally do not feel fundamentalist today ;-)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_line_items(line):\n",
      "    items = line.split()[:-1]\n",
      "    try:\n",
      "        return [float(items[0]), float(items[1]), float(items[2])]\n",
      "    except ValueError:\n",
      "        return [float(items[0]), np.nan, np.nan]\n",
      "\n",
      "load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It works, great!\n",
      "\n",
      "If you already know Python you feel my pain when you see this line where we convert three values into floats. Whenever you do the same thing to multiple elements of a list and you need to get a list back, you should really consider using a [list comprehension](http://docs.python.org/tutorial/datastructures.html#list-comprehensions). After the conversion it becomes more obvious what this line is supposed to do: convert the first three items in that list to float. If we ever want to switch to another datatype there would be only one place to edit, instead of three."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def get_line_items(line):\n",
      "    items = line.split()[:-1]\n",
      "    try:\n",
      "        return [float(i) for i in items[:3]]\n",
      "    except ValueError:\n",
      "        return [float(items[0]), np.nan, np.nan]\n",
      "\n",
      "load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's assemble the complete code for our parser implementation. It looks pretty good. The ``load_data()`` function is pretty concise and readable. The two main peculiarities for handling this file format are factored into dedicated functions.\n",
      "\n",
      "We could take the refactoring even further, by passing the functions to filter data lines and extract line items as arguments to ``load_data()``. This would yield an even more generic implementation that could potentially handle much different file formats. However, we refrain from doing that, because an increased level of abstraction almost always comes with the cost of making the code less intuitive to understand. Moreover, we are not planing (yet) to support more format, so there is no benefit.\n",
      "\n",
      "Anyway, we can confirm that our code works on both data snippets that we have access to."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_dataline(line):\n",
      "    return line[0].isdigit()\n",
      "\n",
      "def get_line_items(line):\n",
      "    items = line.split()[:-1]\n",
      "    try:\n",
      "        return [float(i) for i in items[:3]]\n",
      "    except ValueError:\n",
      "        return [float(items[0]), np.nan, np.nan]\n",
      "\n",
      "def load_data(filename):\n",
      "    data = []\n",
      "    for line in open(filename):\n",
      "        if not is_dataline(line):\n",
      "            continue\n",
      "        data.append(get_line_items(line))\n",
      "    return np.array(data)\n",
      "\n",
      "d1 = load_data(os.path.join('data', 'gaze_snip1.txt'))\n",
      "d2 = load_data(os.path.join('data', 'gaze_snip2.txt'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, showtime: let's try the parser on a full logfile with hundreds of thousands of data samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = load_data(os.path.join('data', 'gaze.txt.gz'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Too bad. I read some kind of character salad. Let's take a look at the first line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "open(os.path.join('data', 'gaze.txt.gz')).readline()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ah, remember? The big data file is compressed.\n",
      "\n",
      "And again Python's amazing standard library comes to the rescue. The [``fileinput``](http://docs.python.org/library/fileinput.html) module provides functionality to read data from a number of sources: from files, from STDIN. What makes it even more awesome is the ``fileinput`` can automatically detect whether data is compressed and handle decompression automatically for us. How cool is that?\n",
      "\n",
      "Instead of adding this functionality directly to ``load_data()``, we'll refactor again: rename ``load_data()`` to ``load_data_in()`` and modify it to expect a handler to a file-like handler, instead of opening the file itself. In addition, we create a new ``load_data()`` function that does nothing but use ``fileinput`` to open a given data file and pass the resulting handler to ``load_data_in()``. If the advantages of this approach are not completely obvious right now, I can promise you'll see it later on. For know let me just mention there are more data sources that have a file-like interface than just files, and with this move we add the ability to read data from more than just files, while keeping our current programming interface intact.\n",
      "\n",
      "Let's check that we can read both, compressed and uncompressed version of the some file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fileinput\n",
      "\n",
      "def load_data(filename):\n",
      "    fi = fileinput.FileInput(filename, openhook=fileinput.hook_compressed)\n",
      "    return load_data_in(fi)\n",
      "\n",
      "def load_data_in(file_like):\n",
      "    data = []\n",
      "    for line in file_like:\n",
      "        if not is_dataline(line):\n",
      "            continue\n",
      "        data.append(get_line_items(line))\n",
      "    return np.array(data)\n",
      "\n",
      "d1 = load_data(os.path.join('data', 'gaze_snip1.txt'))\n",
      "d2 = load_data(os.path.join('data', 'gaze_snip1.txt.gz'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we should really be ready for prime time. Here is the full code to load our big data file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import fileinput\n",
      "\n",
      "def is_dataline(lineno, line):\n",
      "    return line[0].isdigit()\n",
      "\n",
      "def get_line_items(line):\n",
      "    items = line.split()[:-1]\n",
      "    try:\n",
      "        return [float(i) for i in items[:3]]\n",
      "    except ValueError:\n",
      "        return [float(items[0]), np.nan, np.nan]\n",
      "\n",
      "def load_data_in(file_like):\n",
      "    data = []\n",
      "    for lineno, line in enumerate(file_like):\n",
      "        if not is_dataline(lineno, line):\n",
      "            continue\n",
      "        data.append(get_line_items(line))\n",
      "    return np.array(data)\n",
      "\n",
      "def load_data(filename):\n",
      "    fi = fileinput.FileInput(filename, openhook=fileinput.hook_compressed)\n",
      "    return load_data_in(fi)\n",
      "\n",
      "data = load_data(os.path.join('data', 'gaze.txt.gz'))\n",
      "print \"Loaded %i samples\" % len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That took a moment! Let's create that heatmap plot we want. First a 2D histogram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.histogram2d(data[:,1], data[:, 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ha, it can't handle NaNs. So if we want a histogram, we need to deal with them in some way. The simplest is to remove all missing data samples from our array. A little function (with an expressive name) is all we need. Fortunately, ``numpy`` provides a function to test for the presence of ``NaN`` values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def remove_blinks(data):\n",
      "    filtered = []\n",
      "    for samp in data:\n",
      "        if not np.isnan(samp).sum():\n",
      "            filtered.append(samp)\n",
      "    return np.array(filtered)\n",
      "\n",
      "filtered_data = remove_blinks(data)\n",
      "print \"Removed %i samples\" % (len(data) -  len(filtered_data))\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ouch, that also took a while. IPython has a built-in \"magic\" function that can be used to estimate the run time of individual code. it is pretty clever. it will run the respective code multiple times, but less often the longer it runs per iteration.\n",
      "\n",
      "By the way: IPython has quite a bit of [magic](http://ipython.org/ipython-doc/stable/interactive/tutorial.html) built-in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit remove_blinks(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wow, this is code that runs for seconds in 2013. Imagine how long you'd have to wait in 1993!\n",
      "\n",
      "Let's make an attempt to make this a bit more efficient. Keep in mind that the [god father of programming](http://en.wikiquote.org/wiki/Donald_Knuth) taught us that \"premature optimization is the root of all evil\", but here we identified a bit of code that will run every time, and it just takes too long.\n",
      "\n",
      "Let's use a shortcut and assume that whenever the X coordinate of a sample is ``NaN`` we throw the sample away -- and there are no cases where the X cordinate is valid and the Y-coordinate is not. ADD A TEST\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_blinks_arr(data):\n",
      "    blink = np.isnan(data[:,1])\n",
      "    return data[np.logical_not(blink)]\n",
      "\n",
      "filtered_data = remove_blinks_arr(data)\n",
      "print \"Removed %i samples\" % (len(data) -  len(filtered_data))\n",
      "\n",
      "%timeit remove_blinks_arr(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wooohoo! Several orders of magnitude faster.\n",
      "\n",
      "> Side note: Whenever you see a ``for`` loop in Python code, and you can think of a valid algorithm to do the same without an explicit ``for`` loop there could be quite significant performance gains, because of the way the Python interpreter treats these loops.\n",
      "\n",
      "With the missing data removed we can now compute the heatmap. ``histogram2d()`` returns three values: the heatmap, as well as bin boundaries for X and Y axis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "heatmap, xbound, ybound = np.histogram2d(filtered_data[:,1], filtered_data[:, 2])\n",
      "print xbound\n",
      "print ybound"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I can tell you that the monitor had a resolution of 1680x1050 pixels, so this is not very useful. Let's contrain the values to the actual rectangle of screen coordinates to make a more useful plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_data(data):\n",
      "    d = remove_blinks_arr(data)\n",
      "    np.clip(d[:, 1], 0, 1680, d[:, 1])\n",
      "    np.clip(d[:, 2], 0, 1050, d[:, 2])\n",
      "    return d\n",
      "\n",
      "filtered_data = filter_data(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could do this in a dedicated function, but let's postpone this for now to finally see this plot. Notice ``pyplot``'s similarity to the MATLAB plotting facilities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "heatmap, xbound, ybound = np.histogram2d(filtered_data[:,1], filtered_data[:, 2], bins=50)\n",
      "pl.figure()\n",
      "pl.imshow(heatmap, interpolation='nearest')\n",
      "pl.xticks(np.arange(len(xbound))[::5] - 0.5, xbound[::5], rotation=90)\n",
      "pl.yticks(np.arange(len(ybound))[::5] - 0.5 , ybound[::5])\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's turn this into a handy plotting helper function. I promised to show how IPython can pull up help for any function. Here is how it goes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_heatmap_plot(x, y, bins=50, tick_step=5, interpolation='nearest'):\n",
      "    \"\"\"Plot spatial distribution of gaze coordinates\n",
      "\n",
      "    This function cannot handle NaNs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array\n",
      "      x-coordinates\n",
      "    y : array\n",
      "      y-coordinates (need to match length of x-coordinates)\n",
      "    bins : int\n",
      "      number of histogram bins\n",
      "    tick_steps : int\n",
      "      step size for labeling bin boundaries (e.g. 1: reports all,\n",
      "      5: labels every 5th)\n",
      "    interpolation : str\n",
      "      label of a supported interpolation method (e.g. 'bilinear', 'bicubic')\n",
      "      default: nearest neighbor interpolation\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    fig\n",
      "      a reference to the generated matplotlib figure\n",
      "    \"\"\"\n",
      "    heatmap, xbound, ybound = np.histogram2d(x, y, bins=bins)\n",
      "    fig = pl.figure()\n",
      "    pl.imshow(heatmap, interpolation=interpolation)\n",
      "    pl.xticks(np.arange(len(xbound))[::tick_step] - 0.5, xbound[::tick_step], rotation=90)\n",
      "    pl.yticks(np.arange(len(ybound))[::tick_step] - 0.5 , ybound[::tick_step])\n",
      "    return fig\n",
      "\n",
      "fig = make_heatmap_plot(filtered_data[:, 1], filtered_data[:, 2])\n",
      "pl.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A (multi-line) string right after the function definition, not assigned to any variable is consider as documentation by Python. There are some [conventions](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt) how such a ``docstring`` should look like to make it easy for IPython and other applications to do meaningful things with it. Similar docstrings can also be places at the top of module source files. Consequently, in Python, code and its documentation stay very close together -- which will hopefully help to keep to documentation more up-to-date -- hopefully.\n",
      "\n",
      "Let's access the documentation we just wrote."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TYPE THIS: make_heatmap_plot(\n",
      "help(make_heatmap_plot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another nice feature of matplotlib should not go unnoticed. you can save any figure into a variety of formats for example PNG or SVG, where the latter is perfect for postprocessing with [inkscape](http://inkscape.org) for high-quality figures for your publications.\n",
      "\n",
      "Because we exposed a few selected parameters in our plotting function we can easily change the look of the plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = make_heatmap_plot(filtered_data[:, 1], filtered_data[:, 2], bins=5, tick_step=1, interpolation='bicubic')\n",
      "pl.savefig('heatmap.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now at a stage where we can be quite satisfied with our work. Nicely compact and readable code -- semmingly functional.\n",
      "\n",
      "However, with a few more lines, we can make it even better and turn it into a command line tool that doesn't force people to even know about Python. To achieve this we need to restructure our code again. We split it into a module that contains all functionality. It contains all our functions, but nother actually calls them -- a classic library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pycat gaze/utils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The other part is the command line interface. It reads arguments from the command line and calls the appropriate functions accordingly. You'll see that it starts with a [shebang](http://en.wikipedia.org/wiki/Shebang_(Unix)) line that you may have seen in other scripts. It also contains a conditional that make the code execute only if soe magical ``__name__`` variable is set to ``\"__main__\"``. This is Python's way of indicating that a scirpt has been called directly and is not being \"imported\" into another script or library. The only remaining bit of new code is the use of the [``sys``](http://docs.python.org/library/sys.html) module to access command line arguments via the ``argv`` list -- similar to C and other languages."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pycat plot_gaze_heatmap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result is a script that we can call (after having given it execute permissions, i.e. ``chmod +x ...``) with two arguments: the data file to load and the name of the file to store the plot into. Benefitting from ``matplotlib`` we can just change the file name to request the plot in a different graphics format (e.g. ``heatmap.png`` vs. ``heatmap.svg``). Try it!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!./plot_gaze_heatmap data/gaze.txt.gz heatmap.png"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By the way: IPython can also load external images and show them in a notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(filename='heatmap.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's stop playing with the code here. It is always fun to make things more functional and/or faster, but all the time that goes into such work is in imminent danger of having been wasted. Do yourself a favor and read on!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(4 / 2 == 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(1 + 1 == 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Regression tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hand_checked_data = load_data(os.path.join('data', 'gaze.txt.gz'))\n",
      "np.save('hand_checked_gaze_data.npy', hand_checked_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_data = load_data(os.path.join('data', 'gaze.txt.gz'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(new_data == hand_checked_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match = new_data == hand_checked_data\n",
      "match"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.prod(hand_checked_data.shape) - np.sum(match)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hand_checked_data[np.logical_not(match)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.nan == np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.testing import assert_array_equal\n",
      "assert_array_equal([2,3,4], [2,3,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert_array_equal(hand_checked_data, new_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pycat gaze/tests/test_regression.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "PYTHONPATH=. python gaze/tests/test_regression.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Unit tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(is_dataline(\"13214122\t   .\t   .\t    0.0\t...\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(not is_dataline(\"MSG\t4435590 DISPLAY_COORDS 0 0 1679 1049\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(is_dataline(\"1\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(not is_dataline(\" 1\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(get_line_items(\"1 2 3 4\") == [1, 2, 3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert(get_line_items(\"1 2 3\") == [1, 2, 3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nose.tools as nt\n",
      "nt.assert_equal(get_line_items(\"1 2 3\"), [1, 2, 3])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_list_equal(get_line_items(\"1 2 3\"), [1, 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_list_equal(get_line_items(\"1 2 3 4 5\"), [1, 2, 3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_list_equal(get_line_items(\"1 . 3 4 5\"), [1, np.nan, np.nan])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_list_equal(get_line_items(\"1 2 . 4 5\"), [1, np.nan, np.nan])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_list_equal(get_line_items(\"1 . . . .\"), [1, np.nan, np.nan])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_line_items(\". 2 3 4 5\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt.assert_raises(ValueError, get_line_items, \". 2 3 4 5\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nosetests gaze/tests/test_utils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nosetests -v gaze/tests/test_utils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nosetests --with-coverage --cover-package=gaze.utils gaze/tests/test_utils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nosetests --with-coverage --cover-package=gaze.utils gaze/tests/test_utils.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With regression test\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "nosetests -v --with-coverage --cover-package=gaze.utils gaze"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting and clipping are still missing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If X is NaN also Y is NaN\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}